{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\" \n",
    "     width=\"30%\" \n",
    "     align=right\n",
    "     alt=\"Dask logo\">\n",
    "\n",
    "Embarrassingly parallel Workloads\n",
    "--------------------------------------------------\n",
    "\n",
    "This notebook shows using [dask.delayed](http://dask.pydata.org/en/latest/delayed.html) or Futures interface to parallelize generic Python code. \n",
    "\n",
    "This example focuses on using Dask for building large embarrassingly parallel computation as often seen in scientific communities and on High Performance Computing facilities, for example with Monte Carlo methods. This kind of simulations suppose the following:\n",
    " - we have a function that run a heavy computation given some parameters,\n",
    " - we need to compute this function on a lot of different input parameters, each function call being independant\n",
    " - we want to gather all the results in one place for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Dask Client for Dashboard\n",
    "\n",
    "Starting the Dask Client will provide a dashboard which \n",
    "is useful to gain insight on the computation.  We will also need it fot the\n",
    "Future API part of this example. Moreover, as this kind of computation\n",
    "is often launched on super computer or in the Cloud, you will probably end\n",
    "up having to start a cluster and connect a client. See \n",
    "[dask-jobqueue](https://github.com/dask/dask-jobqueue),\n",
    "[dask-kubernetes](https://github.com/dask/dask-kubernetes) or \n",
    "[dask-yarn](https://github.com/dask/dask-yarn) for easy ways to achieve this.\n",
    "\n",
    "The link to the dashboard will become visible when you create the client below.  We recommend having it open on one side of your screen while using your notebook on the other side.  This can take some effort to arrange your windows, but seeing them both at the same is very useful when learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(threads_per_worker=4, n_workers=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your computation calling function\n",
    "\n",
    "This function do a simple operation: adding all numbers of a list/array together, but it sleeps for a random amount of time to simulate real work. In real use cases, this could call another python module, or even run an executable using subprocess module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def costly_simulation(list_param):\n",
    "    time.sleep(random.random())\n",
    "    return sum(list_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "result = costly_simulation([1,2,3,4])\n",
    "print(\"Result = %s\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the set of input parameters to call the function\n",
    "\n",
    "We will generate a set of inputs that we want our simulation evaluated on. Here we use pandas.dataframe, but we could have go with simple list too. Lets say that our simulation is run with four parameters called param_[a-d]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_params = pd.DataFrame(np.random.random(size=(1000, 4)),\n",
    "               columns=['param_a', 'param_b', 'param_c', 'param_d'])\n",
    "input_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call our simulation on all this parameters with basic python code. \n",
    "Note that this is not very clever as we can easily parallelize code. Using module\n",
    "like multiprocessing is a first step, and Dask a second for inter nodes distribution.  \n",
    "\n",
    "Let's only do this on a sample of our parameters as it would be quite long otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = []\n",
    "for args in input_params.values[:10]:\n",
    "    result.append(costly_simulation(args))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Dask Delayed to make our function lazy\n",
    "\n",
    "We can call `dask.delayed` on our funtion to make it lazy.  Rather than compute its result immediately, it record what we want to compute as a task into a graph that we'll run later on parallel hardware.\n",
    "\n",
    "\n",
    "Calling these lazy functions is now almost free.  We're just constructing a (simple) graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import dask\n",
    "delayed = []\n",
    "for args in input_params.values[:10]:\n",
    "    delayed.append(dask.delayed(costly_simulation)(args))\n",
    "print(delayed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in parallel\n",
    "\n",
    "Call `.compute()` when you want your result as a normal Python object\n",
    "\n",
    "If you started `Client()` above then you may want to watch the status page during computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = dask.compute(*delayed)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run this on all of our input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = []\n",
    "for args in input_params.values:\n",
    "    delayed.append(dask.delayed(costly_simulation)(args))\n",
    "    \n",
    "futures = dask.persist(*delayed)  # trigger computation in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this go faster, add additional workers.\n",
    "\n",
    "(although we're still only working on our local machine, this is more practical when using an actual cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    client.cluster.start_worker(ncores=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the Dask dashboard we can see that Dask spreads this work around our cluster, managing load balancing, dependencies, etc..\n",
    "\n",
    "Then get the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dask.compute(*futures)\n",
    "result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Future API\n",
    "\n",
    "Same example can be done using the Future API by using the client object itself. It is a more explicit way of submiting computation to a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures = []\n",
    "for args in input_params.values[:10]:\n",
    "    futures.append(client.submit(costly_simulation, args))\n",
    "    \n",
    "result = client.gather(futures)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the code above can be run in fewer lines with `client.map()` function, allowing to call a given function on a list of parameters.\n",
    "\n",
    "As for delayed, we can only start the computation and not wait for results by not calling `client.gather()` right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures = client.map(costly_simulation, input_params.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then just get the results later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.gather(futures)\n",
    "print(len(results))\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encourage you to watch the [dashboard's status page](../proxy/8787/status) to watch on going computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing some analysis on the results\n",
    "\n",
    "One of the interest of dask here, outside from API simplicity, is that you are able to gather the result for all your simulations in one call. No need to implement complex mechanism or to write individual results in a shared file system or object store.\n",
    "\n",
    "Just get your result, and do some computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will just get the results and expand our initial dataframe to have a nice view of params vs results for our computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = input_params.copy()\n",
    "output['result'] = pd.Series(results, index=output.index)\n",
    "output.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can do some nice statistical plots or save result locally with pandas interface here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "output['result'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['result'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_output = output[output['result'] > 2]\n",
    "print(len(filtered_output))\n",
    "filtered_output.to_csv('/tmp/simulation_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling very large simulation\n",
    "\n",
    "The methods above work really well for a size of input parameters up to 100,000. Above that, Dask scheduler has trouble to handle the amount of task to schedule to workers.\n",
    "\n",
    "In this case, one solution is described in [Avoid to many tasks](http://dask.pydata.org/en/latest/delayed-best-practices.html#avoid-too-many-tasks) doc section of delayed: using Bag API.\n",
    "\n",
    "We just need to convert our input_params sequence into a dask.bag collection, asking for fewer partitions (so at most 100,000, which is already huge), and apply our function on every item of the bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import dask.bag as db\n",
    "b = db.from_sequence(list(input_params.values), npartitions=100)\n",
    "b = b.map(costly_simulation)\n",
    "results_bag = b.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking on Dashboard here, you should see only 100 tasks to run instead of 1000, each taking 10x more time in average, because each one is actually calling our function 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(results) == np.all(results_bag)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dask_rt",
   "language": "python",
   "name": "dask_rt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
