{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask integrates well with machine learning libraries like scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>inproc://192.168.7.20/93787/1\n",
       "  <li><b>Dashboard: </b><a href='http://localhost:8787/status' target='_blank'>http://localhost:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>2.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='inproc://192.168.7.20/93787/1' processes=1 cores=4>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(processes=False, threads_per_worker=4, n_workers=1, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training\n",
    "\n",
    "<img src=\"images/scikit-learn-logo-notext.png\"/> <img src=\"images/joblib_logo.svg\" width=\"20%\"/> \n",
    "\n",
    "Scikit-learn uses [joblib](http://joblib.readthedocs.io/) for single-machine parallelism. This lets you train most estimators (anything that accepts an `n_jobs` parameter) using call the cores of your laptop or workstation.\n",
    "\n",
    "Dask registers a joblib backend. This lets you train those estimators using all the cores of your *cluster*, by changing one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_ml.joblib  # register the distriubted backend\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LassoCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Random Array\n",
    "\n",
    "We'll use scikit-learn to create a pair of random arrays, one for the features `X`, and one for the target `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33858087,  0.10661578, -1.41685748,  0.85416003, -1.13306368,\n",
       "         0.43936999, -0.89155779, -0.57320501,  0.6961914 , -0.31448662,\n",
       "         0.32456905,  3.34340464,  1.53807366, -1.12349946, -1.68874323,\n",
       "        -0.3993426 ,  1.89866847,  0.96504723,  0.66673932, -0.9261896 ],\n",
       "       [ 0.73393777,  0.41953825, -2.20315789,  0.70963521, -0.47589734,\n",
       "         0.18055579, -0.11839911,  0.1566506 , -0.54005911, -3.21362844,\n",
       "        -0.58537196, -0.62717674, -0.69529353, -0.76255876,  0.41663376,\n",
       "        -0.34438597, -0.36720999, -1.26199171, -1.31643299,  2.16659469],\n",
       "       [ 0.91076983, -0.45821806,  0.46588253,  2.58363374,  0.59169886,\n",
       "         0.64780522, -0.51263702, -1.08780596,  0.50648207, -0.36087092,\n",
       "        -0.83027318, -0.96445621, -1.20075522, -0.19168403,  1.25850669,\n",
       "        -0.58273732,  0.92955235,  2.13926301, -0.865342  ,  0.9191456 ],\n",
       "       [ 2.37885291,  1.65703815,  2.06113315, -1.28752591,  1.23545085,\n",
       "        -0.13716117, -0.00335223,  0.6448825 , -0.27093623,  1.33218529,\n",
       "         1.00460161, -0.64936265,  0.03463881,  0.30782757,  0.33387805,\n",
       "         1.68235791,  1.28833135,  1.57027962,  0.30298655,  0.18944653],\n",
       "       [-0.91071195,  0.54805915, -2.20212597, -0.83506392, -0.87408233,\n",
       "         0.8600245 ,  2.09050217,  0.14233697, -0.64147762, -2.36800881,\n",
       "        -0.93227004, -0.93644224, -0.28338756, -1.05242263,  0.87252807,\n",
       "         1.32245229,  2.24786133,  0.70473079, -0.76238665,  1.04816008]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then fit a `LassoCV` model, testing out 500 values of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LassoCV(n_alphas=500, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit that normally, we'd just call `clf.fit(X, y)`. To fit it using the cluster, we just need to use a context manager provided by joblib.\n",
    "We'll pre-scatter the data to each worker, which can help with performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "with joblib.parallel_backend('dask', scatter=[X, y]):\n",
    "    clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 500 training tasks were split among all the workers on the cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
