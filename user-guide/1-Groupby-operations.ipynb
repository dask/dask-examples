{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The groupby operation (split-apply-combine)\n",
    " \n",
    "The `group by` concept: we want to **apply the same function on subsets of your dataframe, based on some key to split the dataframe in subsets**.\n",
    "\n",
    "This operation is also referred to as the \"split-apply-combine\" operation, involving the following steps:\n",
    " \n",
    "* **Splitting** the data into groups based on some criteria\n",
    "* **Applying** a function to each group independently\n",
    "* **Combining** the results into a data structure\n",
    "\n",
    "<img src=\"../images/splitApplyCombine.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Dask Client for Dashboard\n",
    "\n",
    "Starting the Dask Client is optional.  It will provide a dashboard which \n",
    "is useful to gain insight on the computation.  \n",
    "\n",
    "The link to the dashboard will become visible when you create the client below.  We recommend having it open on one side of your screen while using your notebook on the other side.  This can take some effort to arrange your windows, but seeing them both at the same is very useful when learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit='1GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dask Dataframe\n",
    "\n",
    "To illustrate the groupby operation in the image above, let's see how this can be accomplished with Dask in the following steps:\n",
    "\n",
    "- Create a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame({'key':['A','B','C','A','B','C','A','B','C'],\n",
    "                   'data': [0, 5, 10, 5, 10, 15, 10, 15, 20]})\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a dask dataframe from the created pandas dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.from_pandas(pdf, npartitions=5)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the dask dataframe is a lazily-evaluated dataframe object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy Operation\n",
    "\n",
    "Dask provides a `groupby` method for us to do the **split-apply-combine** operation. \n",
    "\n",
    "Using groupby, we will group elements by column **`key`** and compute some aggregations such as `sum`, `mean`, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby(by='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the GroupBy object has been created, several methods are available to perform a computation on the grouped data. \n",
    "\n",
    "An obvious one is aggregation via the [`aggregate` or `agg()`](https://dask.pydata.org/en/latest/dataframe-groupby.html#aggregate) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby(by='key').aggregate('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, one notices that Dask returns a lazily-evaluated object until we ask it to compute the actual result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby(by='key').aggregate('sum').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the result of the aggregation will have the group names as the new index along the grouped axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above can also be accomplished without using the `aggregate` method in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby(by='key').sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby(by='key').mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating functions are the ones that reduce the dimension of the returned objects. Some common aggregating functions are tabulated below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Function**  | **Description**               |\n",
    "|---------------|-------------------------------|\n",
    "| **`mean()`**  | Compute mean of groups        |\n",
    "| **`sum()`**   | Compute sum of groups         |\n",
    "| **`size()`**  | Compute group sizes           |\n",
    "| **`count()`** | Compute count of group        |\n",
    "| **`std()`**   | Standard deviation of groups  |\n",
    "| **`var()`**   | Compute variance of groups    |\n",
    "| **`first()`** | Compute first of group values |\n",
    "| **`last()`**  | Compute last of group values  |\n",
    "| **`min()`**   | Compute min of group values   |\n",
    "| **`max()`**   | Compute max of group values   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying multiple functions at once "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With grouped `dask.dataframe` you can also pass a list or dict of functions to do aggregation with, outputting a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = ddf.groupby(by='key')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(['sum', 'mean', 'std', 'max', 'min']).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting aggregations are named for the functions themselves. If you need to rename, then you can add in a chained operation like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(['sum', 'mean', 'std', 'max', 'min'])\\\n",
    "       .rename(columns={'sum': 'foo_sum', \n",
    "                        'mean': 'bar_mean'})\\\n",
    "        .compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation \n",
    "\n",
    "Sometimes you don't want to aggregate the groups, but transform the values in each group. In Pandas this can be achieved with the `transform()` method for groupby objects. This method returns an object that is indexed the same (same size) as the one being grouped.\n",
    "\n",
    "This method is not yet implemented in Dask (https://github.com/dask/dask/issues/2536). However, we can achieve the same functionality by using a custom implementation which combines `.apply()` + a custom function. \n",
    "\n",
    "For example, suppose we wished to normalize the data within each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.date_range('10/1/1999', periods=1100)\n",
    "ts = pd.DataFrame(data=np.random.normal(0.5, 2, 1100), index=index, columns=['data'])\n",
    "ts = ts.rolling(window=100,min_periods=100).mean().dropna()\n",
    "ts['key'] = ts.index.map(lambda x: x.year)\n",
    "dts = dd.from_pandas(ts, npartitions=1)\n",
    "#dts = dts.rolling(window=100,min_periods=100).mean().dropna()\n",
    "dts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = dts.groupby(by='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg('mean').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(group):\n",
    "    return (group - group.mean()) / group.std()\n",
    "\n",
    "# Transformed Data\n",
    "transformed = grouped.apply(normalize, meta={'data':'float32', 'key': 'int8'})\\\n",
    "                     .drop('key', axis=1)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = dts.merge(transformed, left_index=True, right_index=True, \n",
    "          suffixes=('_original', '_transformed')).compute()\n",
    "compare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect the result to now have mean 0 and standard deviation 1 within each group, which we can easily check by visually comparing the original and transformed data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.drop(columns=['key']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying group by on some real data\n",
    "\n",
    "For this section, we will use titanic dataset available in `data` directory. The original dataset can be found at https://www.kaggle.com/c/titanic/data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read titanic csv file into a Dask dataframe \n",
    "ddf = dd.read_csv(\"../data/titanic.csv\")\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's use `groupby()` to calculate the average age for each gender/sex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby(by='Sex')['Age'].mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the average survival ratio for all passengers on Titanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ddf['Survived'].sum() / len(ddf['Survived'])).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the average survival ratio for passengers younger thatn 25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use filtering/boolean indexing to select our group of interest\n",
    "ddf25 = ddf[ddf['Age'] <= 25]\n",
    "\n",
    "(ddf25['Survived'].sum() / len(ddf25['Survived'])).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a difference in this survival ratio between the sexes? To answer this question, we will need to group by `Sex` and aggregate the mean for each group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ddf.groupby('Sex')['Survived'].agg('mean').compute()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's make a bar plot of the survival ratio for the different classes ('Pclass' column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ddf.groupby('Pclass')['Survived'].agg('mean').compute()\n",
    "p.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying multiple functions to columns in groups\n",
    "\n",
    "To apply multiple functions to a single column in a grouped data, we expand the `agg()` syntax to pass in a list of functions as the value in the aggregation dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.groupby(by=['Pclass', 'Sex'])\\\n",
    "   .agg({'Survived': ['count', 'sum', 'mean'],\n",
    "       'Fare': ['mean', 'min', 'max']})\\\n",
    "   .compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can apply a transformation such as **data normalization** by defining a custom function `normalize()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(group):\n",
    "    return (group - group.mean()) / group.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the fare column\n",
    "ddf.groupby(['Pclass','Sex'])['Fare'].apply(normalize, meta=('x', 'float32')).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "This notebook covers the `groupby()` functionality in Dask. If you are interested in other examples, Dask's [official documentation](http://dask.pydata.org/en/latest/dataframe-groupby.html) is a great source. \n",
    "\n",
    "- Start Dask Client for Dashboard\n",
    "- Create Dask dataframe \n",
    "- GroupBy Operation\n",
    "- Aggregation \n",
    "- Applying multiple functions at once \n",
    "- Transformation \n",
    "- Applying group by on some real data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
